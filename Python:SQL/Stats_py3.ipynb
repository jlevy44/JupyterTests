{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adopted from Jordan Levy's code\n",
    "import requests\n",
    "import urllib\n",
    "import urllib.request\n",
    "import numpy as np, pandas as pd\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "totalArr = np.empty\n",
    "def make_soup(url):\n",
    "    url = urllib.request.urlopen(url)\n",
    "    soupdata = BeautifulSoup(url, \"html.parser\")\n",
    "    return soupdata\n",
    "#data = []\n",
    "def index_containing_substring(the_list, substring):\n",
    "    for i, s in enumerate(the_list):\n",
    "        if substring in s:\n",
    "              return i\n",
    "    return -1\n",
    "for year in map(str,range(2010,2017)):\n",
    "    for week in range(1,18):\n",
    "        savedplayerdata=\"\"\n",
    "        #playerdata = \"\"\n",
    "        soup_proj = make_soup(\"http://www.fftoday.com/rankings/playerwkproj.php?Season=%s&GameWeek=%d&PosID=10&LeagueID=189999\"%(year,week))\n",
    "        # print(soup.find('table',{\"width\":\"100%\", \"cellpadding\":\"2\"}))\n",
    "        \n",
    "\n",
    "        table = soup_proj.find('table', {\"width\": \"100%\", \"cellpadding\": \"2\"})\n",
    "        \n",
    "        #for rows in table.findAll('tr'):\n",
    "        #playerdata=\"\"\n",
    "        #print(table)\n",
    "        playerdata = ','.join([data.text.strip(' ') for data in table.findAll('td', {\"class\":\"bodycontent\"})]).replace('\\xa0,\\xa0','').replace('\\xa0','').split(',')\n",
    "        playerdata = list(filter(lambda a: a != '', playerdata))\n",
    "        playerdata = [playerdata[i:i+12] for i in range(len(playerdata))[::12]]\n",
    "        \n",
    "        soup_actual = make_soup('http://www.fftoday.com/stats/playerstats.php?Season=%s&GameWeek=%d&PosID=10&LeagueID=189999'%(year,week))\n",
    "        table_actual = soup_actual.find('table', {\"width\": \"100%\", \"cellpadding\": \"2\"})\n",
    "\n",
    "\n",
    "        lines = table_actual.text.splitlines()\n",
    "        playerdata_act = lines[index_containing_substring(lines,'.'):]\n",
    "        #print(soup_actual.text)\n",
    "        #playerdata_act = ','.join([data.text.strip(' ') for data in table_actual.findAll('TD', {\"CLASS\":\"sort1\"})]).replace('\\xa0,\\xa0','').replace('\\xa0','').split(',')\n",
    "        playerdata_act = list(filter(lambda a: a != '', playerdata_act))\n",
    "        #print(playerdata_act)\n",
    "        #print(playerdata_act[481])\n",
    "        #print(list(range(len(playerdata_act))[::13]))\n",
    "        playerdata_act = {playerdata_act[i].split('. ')[1]:playerdata_act[i+12] for i in range(len(playerdata_act))[::13]}#playerdata_act[i+11]\n",
    "        #print(playerdata_act)\n",
    "\n",
    "\n",
    "        \n",
    "        #playerdata = [player.replace('\\xa0,\\xa0','').replace('\\xa0','')]\n",
    "\n",
    "        #playerdata+=data.text+\",\"\n",
    "        #print(playerdata)\n",
    "        \n",
    "        playerArr = np.array(playerdata)\n",
    "        playerArr[:,1] = 'QB'\n",
    "        playerArr[:,2] = week\n",
    "        playerArr = np.insert(playerArr,2,int(year),axis=1)\n",
    "        playerArr = np.column_stack([playerArr,np.ones((len(playerArr),1,))])#np.concatenate((playerArr,np.nan((len(playerArr),1,))),axis=1)\n",
    "        #print(playerArr)\n",
    "        playerArr[:,-1] = np.nan\n",
    "        #print(playerArr)\n",
    "        #rmRows = []\n",
    "        for i,player in enumerate(playerArr[:,1]):\n",
    "            try:\n",
    "                playerArr[i,-1] = playerdata_act[playerArr[i,0]]\n",
    "            except:\n",
    "                pass#rmRows.append(i)\n",
    "        #print(rmRows)\n",
    "        #print(playerArr[:,-1])\n",
    "        #print([playerdata_act[player] for player in playerArr[:,0]])\n",
    "        playerArr = playerArr[playerArr[:,-1] != 'nan']#np.delete(playerArr,rmRows,1)\n",
    "        #print(playerArr)\n",
    "        \n",
    "        \n",
    "        #print(playerArr)\n",
    "        #print(playerArr)\n",
    "        if week == 1 and int(year) == 2010:\n",
    "            totalArr = playerArr\n",
    "        else:\n",
    "            totalArr=np.concatenate((totalArr,playerArr),axis=0)\n",
    "            #if totalArr.shape[1] != playerArr.shape[1]:\n",
    "            #    print(playerArr)\n",
    "            #    print(playerdata)\n",
    "            #    print(playerdata_act)\n",
    "#print(totalArr.shape)\n",
    "#print(len(totalArr[1,:]))\n",
    "#print(totalArr)\n",
    "    #print(totalArr)\n",
    "            #print(totalArr)\n",
    "        #playerArr[:,3:] = playerArr[:,3:])\n",
    "        #print(playerArr[10,6]-playerArr[10,7])\n",
    "    #if int(year) == 2010:\n",
    "    #    totalArr2 = totalArr\n",
    "    #else:\n",
    "    #    totalArr2=np.concatenate((totalArr2,totalArr),axis=0)\n",
    "players_train = pd.DataFrame(totalArr)\n",
    "#print(players)\n",
    "#data.append(players)\n",
    "\n",
    "#print(data)\n",
    "#players = players.set_index(0)\n",
    "\n",
    "#print(players)\n",
    "#savedplayerdata= savedplayerdata + \"\\n\" + playerdata[1:]\n",
    "\n",
    "#print(savedplayerdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     0   1     2   3   4   5    6  7  8  9   10 11    12\n",
      "0           Andrew Luck  QB  2016   1  26  42  320  3  1  4  15  0  25.3\n",
      "1            Drew Brees  QB  2016   1  26  40  310  3  1  0   0  0  23.4\n",
      "2        Russell Wilson  QB  2016   1  23  35  265  2  0  7  35  0  22.1\n",
      "3          Tyrod Taylor  QB  2016   1  20  32  255  2  0  6  35  0  21.7\n",
      "4            Cam Newton  QB  2016   1  19  30  225  1  1  8  35  1  21.5\n",
      "5         Aaron Rodgers  QB  2016   1  26  40  280  2  0  4  20  0  21.2\n",
      "6            Alex Smith  QB  2016   1  24  36  260  2  0  5  25  0  20.9\n",
      "7             Matt Ryan  QB  2016   1  22  36  295  2  0  0   0  0  19.8\n",
      "8      Matthew Stafford  QB  2016   1  26  41  305  2  1  1   5  0  19.7\n",
      "9        Jameis Winston  QB  2016   1  23  37  280  2  1  5  15  0  19.7\n",
      "10          Eli Manning  QB  2016   1  25  43  290  2  0  0   0  0  19.6\n",
      "11         Kirk Cousins  QB  2016   1  23  39  300  2  1  2   5  0  19.5\n",
      "12           Derek Carr  QB  2016   1  22  34  285  2  1  3  10  0  19.4\n",
      "13        Philip Rivers  QB  2016   1  24  39  310  2  1  0   0  0  19.4\n",
      "14        Blake Bortles  QB  2016   1  26  43  270  2  1  3  15  0  19.3\n",
      "15     Ryan Fitzpatrick  QB  2016   1  23  36  270  2  1  3  10  0  18.8\n",
      "16   Ben Roethlisberger  QB  2016   1  22  37  295  2  1  0   0  0  18.8\n",
      "17       Brock Osweiler  QB  2016   1  23  35  265  2  0  0   0  0  18.6\n",
      "18         Dak Prescott  QB  2016   1  20  31  240  2  0  2  10  0  18.6\n",
      "19        Carson Palmer  QB  2016   1  23  38  285  2  1  0   0  0  18.4\n",
      "20       Marcus Mariota  QB  2016   1  20  32  240  1  0  4  25  0  16.1\n",
      "21         Carson Wentz  QB  2016   1  25  44  275  1  1  5  20  0  16.0\n",
      "22           Jay Cutler  QB  2016   1  21  34  255  1  1  3  10  0  14.2\n",
      "23       Ryan Tannehill  QB  2016   1  20  33  230  1  1  3  20  0  14.2\n",
      "24      Jimmy Garoppolo  QB  2016   1  22  38  250  1  1  3  10  0  14.0\n",
      "25          Andy Dalton  QB  2016   1  19  32  220  1  0  2  10  0  13.8\n",
      "26       Blaine Gabbert  QB  2016   1  16  29  190  1  1  5  25  0  13.1\n",
      "27   Robert Griffin III  QB  2016   1  18  29  215  1  1  3  15  0  13.1\n",
      "28           Joe Flacco  QB  2016   1  20  31  240  1  1  0   0  0  12.6\n",
      "29       Trevor Siemian  QB  2016   1  20  31  220  1  1  1   5  0  12.3\n",
      "..                  ...  ..   ...  ..  ..  ..  ... .. .. ..  .. ..   ...\n",
      "484           Tom Brady  QB  2016  17  26  38  290  3  0  0   0  0  23.6\n",
      "485         Andrew Luck  QB  2016  17  23  36  275  2  1  4  15  0  19.5\n",
      "486    Matthew Stafford  QB  2016  17  24  37  275  2  1  4  15  0  19.5\n",
      "487          Cam Newton  QB  2016  17  21  35  260  2  1  4  20  0  19.4\n",
      "488          Joe Flacco  QB  2016  17  23  36  280  2  0  0   0  0  19.2\n",
      "489          Alex Smith  QB  2016  17  22  32  220  2  0  4  20  0  18.8\n",
      "490      Jameis Winston  QB  2016  17  22  36  270  2  1  3  10  0  18.8\n",
      "491        Kirk Cousins  QB  2016  17  21  36  275  2  1  2   5  0  18.5\n",
      "492       Philip Rivers  QB  2016  17  23  36  285  2  1  0   0  0  18.4\n",
      "493        Carson Wentz  QB  2016  17  24  41  260  2  1  2  10  0  18.4\n",
      "494        Sam Bradford  QB  2016  17  27  39  255  2  0  0   0  0  18.2\n",
      "495        Matt Barkley  QB  2016  17  22  39  265  2  1  0   0  0  17.6\n",
      "496       Carson Palmer  QB  2016  17  21  35  265  2  1  0   0  0  17.6\n",
      "497        Landry Jones  QB  2016  17  19  30  225  2  1  1  10  0  17.0\n",
      "498    Colin Kaepernick  QB  2016  17  16  27  200  1  1  6  40  0  15.0\n",
      "499  Robert Griffin III  QB  2016  17  17  27  205  1  1  6  35  0  14.7\n",
      "500       Blake Bortles  QB  2016  17  24  40  255  1  1  2  10  0  14.2\n",
      "501           EJ Manuel  QB  2016  17  20  31  215  1  1  5  25  0  14.1\n",
      "502          Tom Savage  QB  2016  17  20  32  245  1  1  2   5  0  13.3\n",
      "503        Matt McGloin  QB  2016  17  20  34  230  1  1  2  10  0  13.2\n",
      "504         Andy Dalton  QB  2016  17  20  33  225  1  1  2  10  0  13.0\n",
      "505         Eli Manning  QB  2016  17  19  32  220  1  1  0   0  0  11.8\n",
      "506          Matt Moore  QB  2016  17  20  33  220  1  1  0   0  0  11.8\n",
      "507         Matt Cassel  QB  2016  17  18  29  215  1  2  2  10  0  11.6\n",
      "508    Ryan Fitzpatrick  QB  2016  17  18  31  225  1  2  0   0  0  11.0\n",
      "509          Jared Goff  QB  2016  17  13  26  180  1  1  1   5  0  10.7\n",
      "510        Mark Sanchez  QB  2016  17  14  22  165  1  1  2   5  0  10.1\n",
      "511        Dak Prescott  QB  2016  17   7  11   85  1  0  2  10  0   8.4\n",
      "512      Trevor Siemian  QB  2016  17   8  13   95  1  0  1   5  0   8.3\n",
      "513           Tony Romo  QB  2016  17   3   5   35  0  0  0   0  0   1.4\n",
      "\n",
      "[514 rows x 13 columns]\n"
     ]
    }
   ],
   "source": [
    "# grab 2017 projection data\n",
    "year = '2016'\n",
    "def make_soup(url):\n",
    "    url = urllib.request.urlopen(url)\n",
    "    soupdata = BeautifulSoup(url, \"html.parser\")\n",
    "    return soupdata\n",
    "#data = []\n",
    "def index_containing_substring(the_list, substring):\n",
    "    for i, s in enumerate(the_list):\n",
    "        if substring in s:\n",
    "              return i\n",
    "    return -1\n",
    "for week in range(1,18):\n",
    "    savedplayerdata=\"\"\n",
    "    #playerdata = \"\"\n",
    "    soup_proj = make_soup(\"http://www.fftoday.com/rankings/playerwkproj.php?Season=%s&GameWeek=%d&PosID=10&LeagueID=189999\"%(year,week))\n",
    "    # print(soup.find('table',{\"width\":\"100%\", \"cellpadding\":\"2\"}))\n",
    "\n",
    "\n",
    "    table = soup_proj.find('table', {\"width\": \"100%\", \"cellpadding\": \"2\"})\n",
    "\n",
    "    #for rows in table.findAll('tr'):\n",
    "    #playerdata=\"\"\n",
    "    playerdata = ','.join([data.text.strip(' ') for data in table.findAll('td', {\"class\":\"bodycontent\"})]).replace('\\xa0,\\xa0','').replace('\\xa0','').split(',')\n",
    "    #print(playerdata)\n",
    "    playerdata = list(filter(lambda a: a != '', playerdata))\n",
    "    playerdata = [playerdata[i:i+12] for i in range(len(playerdata))[::12]]\n",
    "    playerArr = np.array(playerdata)\n",
    "    playerArr[:,1] = 'QB'\n",
    "    playerArr[:,2] = week\n",
    "    playerArr = np.insert(playerArr,2,int(year),axis=1)\n",
    "    soup_actual = make_soup('http://www.fftoday.com/stats/playerstats.php?Season=%s&GameWeek=%d&PosID=10&LeagueID=189999'%(year,week))\n",
    "    table_actual = soup_actual.find('table', {\"width\": \"100%\", \"cellpadding\": \"2\"})\n",
    "\n",
    "\n",
    "    lines = table_actual.text.splitlines()\n",
    "    playerdata_act = lines[index_containing_substring(lines,'.'):]\n",
    "    playerdata_act = list(filter(lambda a: a != '', playerdata_act))\n",
    "\n",
    "    playerdata_act = {playerdata_act[i].split('. ')[1]:playerdata_act[i+12] for i in range(len(playerdata_act))[::13]}#playerdata_act[i+11]\n",
    "\n",
    "    playerArr = np.array(playerdata)\n",
    "    playerArr[:,1] = 'QB'\n",
    "    playerArr[:,2] = week\n",
    "    playerArr = np.insert(playerArr,2,int(year),axis=1)\n",
    "    playerArr = np.column_stack([playerArr,np.ones((len(playerArr),1,))])#np.concatenate((playerArr,np.nan((len(playerArr),1,))),axis=1)\n",
    "    playerArr[:,-1] = np.nan\n",
    "\n",
    "    for i,player in enumerate(playerArr[:,1]):\n",
    "        try:\n",
    "            playerArr[i,-1] = playerdata_act[playerArr[i,0]]\n",
    "        except:\n",
    "            pass#rmRows.append(i)\n",
    "\n",
    "    playerArr = playerArr[playerArr[:,-1] != 'nan']\n",
    "    if week == 1:\n",
    "        totalArr = playerArr\n",
    "    else:\n",
    "        totalArr=np.concatenate((totalArr,playerArr),axis=0)\n",
    "    \n",
    "\n",
    "players_test = pd.DataFrame(totalArr)\n",
    "del players_test[13]\n",
    "print(players_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 33.5  31.4  12.9   5.5  22.2  23.6  29.   22.4  26.1  26.5  19.3  12.\n",
      "  18.4  14.6  16.   16.1  22.8  17.6  10.3  18.9  17.7  19.2  12.8  15.1\n",
      "  13.8  18.3  15.1  10.3  12.   11.1  10.2   4.2  30.8  20.6  12.3   3.6\n",
      "  18.4  25.   11.6  11.1  19.6  16.5  26.8  12.6  24.3  21.8  14.5  21.1\n",
      "  12.4  23.8  18.3  17.6   8.6  19.3   3.3  22.7  25.1  25.4  21.4  16.4\n",
      "  18.2  10.3  19.1  10.1  14.5  26.9  11.4  16.1  12.9  19.9  21.   14.2\n",
      "  26.4  13.2  16.   21.    6.8   8.1   8.   14.    3.7   7.5  26.5  27.5\n",
      "  13.8  19.3   6.   17.4  18.4  11.2  23.5  14.9  10.6  29.   14.7   7.7\n",
      "  13.6  19.8   8.2  18.7  18.3  18.7  23.8  25.9  14.6  36.5  31.9  11.9\n",
      "  17.6   6.7  20.   12.5  13.8   9.4   8.6  19.8  13.1  16.6   9.1  23.9\n",
      "  13.5  18.1  15.1   8.5  12.1  18.   17.9  28.4  21.   29.2  22.2  18.8\n",
      "  29.6   7.5  10.1  13.4  13.3  23.8   5.6  13.   15.1  10.4  12.8  13.7\n",
      "  15.   22.2  15.8  17.5  17.9  30.5  18.6  21.5   8.8   6.5  26.   33.6\n",
      "  27.2  10.8  12.4  13.5  28.2  11.5  24.4   8.9  11.1  11.9  12.1  28.8\n",
      "  21.9   9.6   6.2  17.4   7.4  26.1  10.4  13.3  20.   22.6  19.5  18.3\n",
      "  18.1  12.3  30.5  21.7  18.2  22.3  14.7  16.7  17.8  15.6  23.7  20.3\n",
      "   2.   12.4  15.1  21.7  21.9   7.6  25.7  27.8   8.8   7.5  17.3  14.5\n",
      "  15.1   6.1  14.2   7.9  11.9  10.2   4.8  14.3   8.5   3.1  30.1  35.8\n",
      "  18.1  19.4  19.9  13.6  31.8  20.5  24.4  23.5  14.4  12.8  16.8  20.7\n",
      "  25.2  15.7  10.2  10.   20.6  27.7  28.3  10.1  13.1  11.8   7.8  14.3\n",
      "  18.7  27.2  24.7  24.9  29.8  14.7  27.9  14.6  22.5  23.9   9.7  23.8\n",
      "  14.9  11.2  14.8  13.8  23.9  15.8  23.2  12.3  19.9   7.7  26.3  13.2\n",
      "  16.3  12.2  29.5  13.7  24.8  26.5  28.6  12.3  12.7  22.1  21.   16.7\n",
      "   7.9  18.8  19.5  28.4  23.    8.   16.6  16.8   8.2  20.   23.9  18.4\n",
      "   7.4   9.5  19.3   7.7  19.2  14.3  12.4  19.7  16.4  28.4  29.3  16.8\n",
      "  22.6  22.5  17.3  20.4  27.4  25.6   6.7  14.4  17.4  17.2  15.   14.9\n",
      "   9.5  19.4  15.4   8.7  11.1  15.8  13.4   4.3  14.6   6.5  23.1  19.\n",
      "  16.3  21.4  21.6  12.   21.7  32.5  30.2  20.8  20.7  18.6  19.3  17.\n",
      "  18.5  15.1  19.6  34.1  21.1  20.4  13.   14.3   8.   12.7  12.9  29.\n",
      "  10.8  16.9  16.3  26.8  17.6  22.6  14.9  18.8   2.2  10.   23.8  29.7\n",
      "  17.   17.2  12.5  16.   16.8  18.1  17.8  18.6   2.5  14.3  13.7  23.9\n",
      "  13.6  14.9   8.3  11.3  12.5  14.9  22.2  30.2  10.    8.    5.3  12.1\n",
      "  17.   11.6  10.5   5.   18.2  12.5  16.9  21.2  21.5  27.1  10.4   7.5\n",
      "   9.   20.1  18.4  11.9  17.4  12.3   5.6  10.3  17.4  14.1   4.7  12.5\n",
      "   6.5  16.3   7.3   8.7  18.8  15.6  11.2  11.6  15.2  10.7  29.4  19.3\n",
      "  17.4  21.4  15.9  12.   12.6  20.   13.1  18.8   7.4  13.5  12.    8.6\n",
      "  11.4  10.7  11.2  14.9  16.   20.7   6.4  19.2  12.6   8.2  18.6  24.4\n",
      "   9.4  -0.1  17.5   5.4  20.   20.6  16.1  19.9  25.1  31.6   8.3  37.2\n",
      "  13.5  18.5  24.7  21.9  13.5  29.8  24.   25.8   6.3  21.1  13.5  15.2\n",
      "  15.3   8.1  16.2  15.9  23.4  31.2  10.8  11.8  13.7  17.7  -1.    6.\n",
      "  14.7  32.2  29.4  21.   23.6  19.5  20.9  11.1   9.7  25.7  10.9  13.5\n",
      "  16.9  19.1  23.4   1.   21.2  22.1  14.2  17.5  14.1   2.2  -0.9   0.8\n",
      "  13.4   7.2  15.2   9.2  16.4   4.8   1.4   2.4  14.7   5.2]\n",
      "[(514,), (514,), (514,), (514,)]\n",
      "                 Player Projection Actual Score My Computed Score  \\\n",
      "0           Andrew Luck       25.3         33.5           22.2586   \n",
      "1            Drew Brees       23.4         31.4           21.7886   \n",
      "2        Russell Wilson       22.1         12.9           20.9619   \n",
      "3          Tyrod Taylor       21.7          5.5            20.681   \n",
      "4            Cam Newton       21.5         22.2           16.7107   \n",
      "5         Aaron Rodgers       21.2         23.6           18.8688   \n",
      "6            Alex Smith       20.9           29           18.6685   \n",
      "7             Matt Ryan       19.8         22.4           19.1294   \n",
      "8      Matthew Stafford       19.7         26.1           19.2639   \n",
      "9        Jameis Winston       19.7         26.5           17.5671   \n",
      "10          Eli Manning       19.6         19.3           17.1603   \n",
      "11         Kirk Cousins       19.5           12           17.5139   \n",
      "12           Derek Carr       19.4         18.4           18.2979   \n",
      "13        Philip Rivers       19.4         14.6           19.3967   \n",
      "14        Blake Bortles       19.3           16           16.6797   \n",
      "15     Ryan Fitzpatrick       18.8         16.1           16.8183   \n",
      "16   Ben Roethlisberger       18.8         22.8           18.4178   \n",
      "17       Brock Osweiler       18.6         17.6           17.6497   \n",
      "18         Dak Prescott       18.6         10.3           17.0997   \n",
      "19        Carson Palmer       18.4         18.9            17.859   \n",
      "20       Marcus Mariota       16.1         17.7           17.2188   \n",
      "21         Carson Wentz         16         19.2           16.3572   \n",
      "22           Jay Cutler       14.2         12.8           16.7167   \n",
      "23       Ryan Tannehill       14.2         15.1           15.8541   \n",
      "24      Jimmy Garoppolo         14         13.8           15.2425   \n",
      "25          Andy Dalton       13.8         18.3           14.6779   \n",
      "26       Blaine Gabbert       13.1         15.1           13.2543   \n",
      "27   Robert Griffin III       13.1         10.3           14.4409   \n",
      "28           Joe Flacco       12.6           12           16.2263   \n",
      "29       Trevor Siemian       12.3         11.1           14.6447   \n",
      "..                  ...        ...          ...               ...   \n",
      "484           Tom Brady       23.6         23.6           20.7311   \n",
      "485         Andrew Luck       19.5         19.5           17.9177   \n",
      "486    Matthew Stafford       19.5         20.9           17.9632   \n",
      "487          Cam Newton       19.4         11.1           17.6067   \n",
      "488          Joe Flacco       19.2          9.7           17.6739   \n",
      "489          Alex Smith       18.8         25.7           16.9789   \n",
      "490      Jameis Winston       18.8         10.9            16.733   \n",
      "491        Kirk Cousins       18.5         13.5           16.3777   \n",
      "492       Philip Rivers       18.4         16.9           17.9538   \n",
      "493        Carson Wentz       18.4         19.1           15.4906   \n",
      "494        Sam Bradford       18.2         23.4           16.0421   \n",
      "495        Matt Barkley       17.6            1             15.53   \n",
      "496       Carson Palmer       17.6         21.2           16.1879   \n",
      "497        Landry Jones         17         22.1           14.4281   \n",
      "498    Colin Kaepernick         15         14.2           15.8641   \n",
      "499  Robert Griffin III       14.7         17.5           15.6756   \n",
      "500       Blake Bortles       14.2         14.1           15.3521   \n",
      "501           EJ Manuel       14.1          2.2           14.2605   \n",
      "502          Tom Savage       13.3         -0.9           14.7916   \n",
      "503        Matt McGloin       13.2          0.8            13.344   \n",
      "504         Andy Dalton         13         13.4           13.0535   \n",
      "505         Eli Manning       11.8          7.2           12.3356   \n",
      "506          Matt Moore       11.8         15.2            12.588   \n",
      "507         Matt Cassel       11.6          9.2           11.1342   \n",
      "508    Ryan Fitzpatrick         11         16.4            11.975   \n",
      "509          Jared Goff       10.7          4.8           9.03223   \n",
      "510        Mark Sanchez       10.1          1.4           8.96905   \n",
      "511        Dak Prescott        8.4          2.4           8.71472   \n",
      "512      Trevor Siemian        8.3         14.7           8.55353   \n",
      "513           Tony Romo        1.4          5.2           4.84639   \n",
      "\n",
      "    actual-projection actual-model  \n",
      "0                 8.2      11.2414  \n",
      "1                   8      9.61141  \n",
      "2                -9.2     -8.06189  \n",
      "3               -16.2      -15.181  \n",
      "4                 0.7      5.48929  \n",
      "5                 2.4      4.73121  \n",
      "6                 8.1      10.3315  \n",
      "7                 2.6       3.2706  \n",
      "8                 6.4      6.83615  \n",
      "9                 6.8      8.93295  \n",
      "10               -0.3      2.13975  \n",
      "11               -7.5     -5.51395  \n",
      "12                 -1     0.102098  \n",
      "13               -4.8     -4.79674  \n",
      "14               -3.3    -0.679691  \n",
      "15               -2.7    -0.718318  \n",
      "16                  4      4.38218  \n",
      "17                 -1   -0.0496803  \n",
      "18               -8.3      -6.7997  \n",
      "19                0.5      1.04099  \n",
      "20                1.6     0.481208  \n",
      "21                3.2      2.84284  \n",
      "22               -1.4     -3.91672  \n",
      "23                0.9    -0.754093  \n",
      "24               -0.2     -1.44245  \n",
      "25                4.5      3.62206  \n",
      "26                  2       1.8457  \n",
      "27               -2.8     -4.14089  \n",
      "28               -0.6     -4.22633  \n",
      "29               -1.2     -3.54471  \n",
      "..                ...          ...  \n",
      "484                 0      2.86894  \n",
      "485                 0       1.5823  \n",
      "486               1.4      2.93677  \n",
      "487              -8.3     -6.50672  \n",
      "488              -9.5     -7.97392  \n",
      "489               6.9      8.72113  \n",
      "490              -7.9     -5.83295  \n",
      "491                -5     -2.87771  \n",
      "492              -1.5     -1.05383  \n",
      "493               0.7      3.60944  \n",
      "494               5.2      7.35793  \n",
      "495             -16.6       -14.53  \n",
      "496               3.6      5.01215  \n",
      "497               5.1      7.67195  \n",
      "498              -0.8     -1.66413  \n",
      "499               2.8      1.82444  \n",
      "500              -0.1     -1.25215  \n",
      "501             -11.9     -12.0605  \n",
      "502             -14.2     -15.6916  \n",
      "503             -12.4      -12.544  \n",
      "504               0.4     0.346538  \n",
      "505              -4.6     -5.13557  \n",
      "506               3.4      2.61199  \n",
      "507              -2.4      -1.9342  \n",
      "508               5.4        4.425  \n",
      "509              -5.9     -4.23223  \n",
      "510              -8.7     -7.56905  \n",
      "511                -6     -6.31472  \n",
      "512               6.4      6.14647  \n",
      "513               3.8     0.353613  \n",
      "\n",
      "[514 rows x 6 columns]\n",
      "Average Residual Error for actual-projection = -1.198833 ± 6.798123 and actual - model =  0.010068 ± 6.527267\n",
      " For model to work, second number must be less than first number\n"
     ]
    }
   ],
   "source": [
    "#print(np.vectorize(float)(players_test[:,3:]))\n",
    "#players_test = pd.DataFrame(totalArr)\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "#print(players_train.loc[:,3:13].values)\n",
    "stdS = StandardScaler()\n",
    "\n",
    "trainData = np.vectorize(float)(players_train.loc[:,3:12].values)\n",
    "stdS.fit(trainData)\n",
    "trainData = stdS.transform(trainData)\n",
    "trainLabels = np.vectorize(float)(players_train.loc[:,13].values)\n",
    "testData = stdS.transform(np.vectorize(float)(players_test.loc[:,3:].values))\n",
    "#print(trainData.shape,trainLabels.shape,testData.shape)\n",
    "#print(pd.DataFrame(trainData),pd.DataFrame(trainLabels),pd.DataFrame(testData))\n",
    "mlp = MLPRegressor()\n",
    "#print(np.vectorize(float)(players_train.loc[:,3:13].values),np.vectorize(float)(players_train.loc[:,13].values,players_test.loc[:,3:].values)\n",
    "mlp.fit(trainData,trainLabels)\n",
    "a = mlp.predict(testData)\n",
    "#print(players_train[players_train[2] == '2016'].loc[:,13].values)\n",
    "print(np.vectorize(float)(players_train[players_train[2] == '2016'].loc[:,13].values))\n",
    "playernames = players_test.loc[:,0].values\n",
    "actual = np.vectorize(float)(players_train[players_train[2] == '2016'].loc[:,13].values)\n",
    "predicted = np.vectorize(float)(players_train[players_train[2] == '2016'].loc[:,12].values)\n",
    "err1, err2 = actual - predicted , actual - a#, predicted - actual\n",
    "av1, av2 = tuple(np.mean(x) for x in [err1,err2])#,err3])#tuple([(np.sum(np.vectorize(lambda x: x**(2))(err))/len(a))**(1/2) for err in [err1,err2,err3]])\n",
    "std1, std2 = np.std(err1), np.std(err2)\n",
    "print([x.shape for x in [playernames,predicted,actual,a]])\n",
    "print(pd.DataFrame(np.column_stack([playernames,predicted,actual,a,err1,err2]),columns=['Player','Projection','Actual Score','My Computed Score','actual-projection','actual-model']))\n",
    "print('Average Residual Error for actual-projection = %f ± %f and actual - model =  %f ± %f\\n For model to work, second number must be less than first number'%(av1,std1,av2,std2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     0   1     2   3   4   5    6  7  8  9   10 11    12    13\n",
      "0           Andrew Luck  QB  2016   1  26  42  320  3  1  4  15  0  25.3  41.5\n",
      "1            Drew Brees  QB  2016   1  26  40  310  3  1  0   0  0  23.4  39.4\n",
      "2        Russell Wilson  QB  2016   1  23  35  265  2  0  7  35  0  22.1  13.9\n",
      "3          Tyrod Taylor  QB  2016   1  20  32  255  2  0  6  35  0  21.7   5.5\n",
      "4            Cam Newton  QB  2016   1  19  30  225  1  1  8  35  1  21.5  23.2\n",
      "5         Aaron Rodgers  QB  2016   1  26  40  280  2  0  4  20  0  21.2  27.6\n",
      "6            Alex Smith  QB  2016   1  24  36  260  2  0  5  25  0  20.9  32.0\n",
      "7             Matt Ryan  QB  2016   1  22  36  295  2  0  0   0  0  19.8  26.4\n",
      "8      Matthew Stafford  QB  2016   1  26  41  305  2  1  1   5  0  19.7  32.1\n",
      "9        Jameis Winston  QB  2016   1  23  37  280  2  1  5  15  0  19.7  33.5\n",
      "10          Eli Manning  QB  2016   1  25  43  290  2  0  0   0  0  19.6  24.3\n",
      "11         Kirk Cousins  QB  2016   1  23  39  300  2  1  2   5  0  19.5  10.0\n",
      "12           Derek Carr  QB  2016   1  22  34  285  2  1  3  10  0  19.4  20.4\n",
      "13        Blake Bortles  QB  2016   1  26  43  270  2  1  3  15  0  19.3  17.0\n",
      "14     Ryan Fitzpatrick  QB  2016   1  23  36  270  2  1  3  10  0  18.8  19.1\n",
      "15   Ben Roethlisberger  QB  2016   1  22  37  295  2  1  0   0  0  18.8  27.8\n",
      "16       Brock Osweiler  QB  2016   1  23  35  265  2  0  0   0  0  18.6  20.6\n",
      "17         Dak Prescott  QB  2016   1  20  31  240  2  0  2  10  0  18.6  10.3\n",
      "18        Carson Palmer  QB  2016   1  23  38  285  2  1  0   0  0  18.4  22.9\n",
      "19       Marcus Mariota  QB  2016   1  20  32  240  1  0  4  25  0  16.1  20.7\n",
      "20         Carson Wentz  QB  2016   1  25  44  275  1  1  5  20  0  16.0  23.2\n",
      "21           Jay Cutler  QB  2016   1  21  34  255  1  1  3  10  0  14.2  13.8\n",
      "22       Ryan Tannehill  QB  2016   1  20  33  230  1  1  3  20  0  14.2  15.1\n",
      "23      Jimmy Garoppolo  QB  2016   1  22  38  250  1  1  3  10  0  14.0  15.8\n",
      "24          Andy Dalton  QB  2016   1  19  32  220  1  0  2  10  0  13.8  19.3\n",
      "25       Blaine Gabbert  QB  2016   1  16  29  190  1  1  5  25  0  13.1  17.1\n",
      "26   Robert Griffin III  QB  2016   1  18  29  215  1  1  3  15  0  13.1   9.3\n",
      "27           Joe Flacco  QB  2016   1  20  31  240  1  1  0   0  0  12.6  14.0\n",
      "28       Trevor Siemian  QB  2016   1  20  31  220  1  1  1   5  0  12.3  11.1\n",
      "29           Shaun Hill  QB  2016   1  19  32  220  1  1  0   0  0  11.8  10.2\n",
      "..                  ...  ..   ...  ..  ..  ..  ... .. .. ..  .. ..   ...   ...\n",
      "467          Drew Brees  QB  2016  17  28  45  325  3  1  0   0  0  24.0  24.0\n",
      "468           Tom Brady  QB  2016  17  26  38  290  3  0  0   0  0  23.6  29.6\n",
      "469         Andrew Luck  QB  2016  17  23  36  275  2  1  4  15  0  19.5  22.5\n",
      "470    Matthew Stafford  QB  2016  17  24  37  275  2  1  4  15  0  19.5  23.9\n",
      "471          Cam Newton  QB  2016  17  21  35  260  2  1  4  20  0  19.4  10.1\n",
      "472          Joe Flacco  QB  2016  17  23  36  280  2  0  0   0  0  19.2   8.7\n",
      "473          Alex Smith  QB  2016  17  22  32  220  2  0  4  20  0  18.8  28.7\n",
      "474      Jameis Winston  QB  2016  17  22  36  270  2  1  3  10  0  18.8  11.9\n",
      "475        Kirk Cousins  QB  2016  17  21  36  275  2  1  2   5  0  18.5  13.5\n",
      "476       Philip Rivers  QB  2016  17  23  36  285  2  1  0   0  0  18.4  18.9\n",
      "477        Sam Bradford  QB  2016  17  27  39  255  2  0  0   0  0  18.2  28.4\n",
      "478        Matt Barkley  QB  2016  17  22  39  265  2  1  0   0  0  17.6  -1.0\n",
      "479       Carson Palmer  QB  2016  17  21  35  265  2  1  0   0  0  17.6  26.2\n",
      "480        Landry Jones  QB  2016  17  19  30  225  2  1  1  10  0  17.0  27.1\n",
      "481    Colin Kaepernick  QB  2016  17  16  27  200  1  1  6  40  0  15.0  16.2\n",
      "482  Robert Griffin III  QB  2016  17  17  27  205  1  1  6  35  0  14.7  20.5\n",
      "483       Blake Bortles  QB  2016  17  24  40  255  1  1  2  10  0  14.2  16.1\n",
      "484           EJ Manuel  QB  2016  17  20  31  215  1  1  5  25  0  14.1   2.2\n",
      "485          Tom Savage  QB  2016  17  20  32  245  1  1  2   5  0  13.3  -0.9\n",
      "486        Matt McGloin  QB  2016  17  20  34  230  1  1  2  10  0  13.2   0.8\n",
      "487         Andy Dalton  QB  2016  17  20  33  225  1  1  2  10  0  13.0  15.4\n",
      "488         Eli Manning  QB  2016  17  19  32  220  1  1  0   0  0  11.8   7.2\n",
      "489          Matt Moore  QB  2016  17  20  33  220  1  1  0   0  0  11.8  18.2\n",
      "490         Matt Cassel  QB  2016  17  18  29  215  1  2  2  10  0  11.6  10.2\n",
      "491    Ryan Fitzpatrick  QB  2016  17  18  31  225  1  2  0   0  0  11.0  20.4\n",
      "492          Jared Goff  QB  2016  17  13  26  180  1  1  1   5  0  10.7   4.8\n",
      "493        Mark Sanchez  QB  2016  17  14  22  165  1  1  2   5  0  10.1  -0.6\n",
      "494        Dak Prescott  QB  2016  17   7  11   85  1  0  2  10  0   8.4   2.4\n",
      "495      Trevor Siemian  QB  2016  17   8  13   95  1  0  1   5  0   8.3  17.7\n",
      "496           Tony Romo  QB  2016  17   3   5   35  0  0  0   0  0   1.4   7.2\n",
      "\n",
      "[497 rows x 14 columns]\n",
      "                      0   1     2   3   4   5    6  7  8  9   10 11    12  \\\n",
      "0         Peyton Manning  QB  2010   1  24  37  290  3  0  0   0  0  23.6   \n",
      "1             Drew Brees  QB  2010   1  27  42  300  3  1  0   0  0  23.0   \n",
      "2          Aaron Rodgers  QB  2010   1  27  44  310  2  0  4  15  0  21.9   \n",
      "3             Jay Cutler  QB  2010   1  25  41  300  2  0  2   5  0  20.5   \n",
      "4              Tony Romo  QB  2010   1  24  39  290  2  0  0   0  0  19.6   \n",
      "5            Matt Schaub  QB  2010   1  24  38  290  2  0  0   0  0  19.6   \n",
      "6             Kevin Kolb  QB  2010   1  24  41  280  2  1  4  10  0  19.2   \n",
      "7            Eli Manning  QB  2010   1  23  38  260  2  0  2   5  0  18.9   \n",
      "8       Matthew Stafford  QB  2010   1  24  40  270  2  0  0   0  0  18.8   \n",
      "9              Tom Brady  QB  2010   1  22  34  260  2  0  0   0  0  18.4   \n",
      "10         Carson Palmer  QB  2010   1  22  34  250  2  0  0   0  0  18.0   \n",
      "11           Brett Favre  QB  2010   1  24  39  270  2  1  0   0  0  17.8   \n",
      "12        Jason Campbell  QB  2010   1  20  34  230  2  0  1   5  0  17.7   \n",
      "13            Kyle Orton  QB  2010   1  22  38  240  2  1  3  10  0  17.6   \n",
      "14        Donovan McNabb  QB  2010   1  20  33  230  2  1  2  10  0  17.2   \n",
      "15             Matt Ryan  QB  2010   1  22  36  250  2  1  0   0  0  17.0   \n",
      "16            Alex Smith  QB  2010   1  23  40  250  2  1  0   0  0  17.0   \n",
      "17        Derek Anderson  QB  2010   1  20  34  235  2  1  2   5  0  16.9   \n",
      "18       Matt Hasselbeck  QB  2010   1  20  33  230  2  1  1   5  0  16.7   \n",
      "19         Philip Rivers  QB  2010   1  23  36  280  1  0  0   0  0  15.2   \n",
      "20         David Garrard  QB  2010   1  18  29  210  1  0  4  20  0  14.4   \n",
      "21          Josh Freeman  QB  2010   1  18  29  200  1  0  5  20  0  14.0   \n",
      "22          Dennis Dixon  QB  2010   1  17  29  195  1  0  5  20  0  13.8   \n",
      "23            Matt Moore  QB  2010   1  19  31  220  1  0  3  10  0  13.8   \n",
      "24           Vince Young  QB  2010   1  18  29  200  1  1  4  20  0  13.0   \n",
      "25         Trent Edwards  QB  2010   1  19  31  210  1  1  3  10  0  12.4   \n",
      "26            Chad Henne  QB  2010   1  21  36  230  1  1  0   0  0  12.2   \n",
      "27           Matt Cassel  QB  2010   1  18  31  200  1  0  0   0  0  12.0   \n",
      "28          Mark Sanchez  QB  2010   1  15  26  170  1  0  1   5  0  11.3   \n",
      "29         Jake Delhomme  QB  2010   1  15  24  180  1  0  0   0  0  11.2   \n",
      "...                  ...  ..   ...  ..  ..  ..  ... .. .. ..  .. ..   ...   \n",
      "3529           Tom Brady  QB  2016  17  26  38  290  3  0  0   0  0  23.6   \n",
      "3530         Andrew Luck  QB  2016  17  23  36  275  2  1  4  15  0  19.5   \n",
      "3531    Matthew Stafford  QB  2016  17  24  37  275  2  1  4  15  0  19.5   \n",
      "3532          Cam Newton  QB  2016  17  21  35  260  2  1  4  20  0  19.4   \n",
      "3533          Joe Flacco  QB  2016  17  23  36  280  2  0  0   0  0  19.2   \n",
      "3534          Alex Smith  QB  2016  17  22  32  220  2  0  4  20  0  18.8   \n",
      "3535      Jameis Winston  QB  2016  17  22  36  270  2  1  3  10  0  18.8   \n",
      "3536        Kirk Cousins  QB  2016  17  21  36  275  2  1  2   5  0  18.5   \n",
      "3537       Philip Rivers  QB  2016  17  23  36  285  2  1  0   0  0  18.4   \n",
      "3538        Carson Wentz  QB  2016  17  24  41  260  2  1  2  10  0  18.4   \n",
      "3539        Sam Bradford  QB  2016  17  27  39  255  2  0  0   0  0  18.2   \n",
      "3540        Matt Barkley  QB  2016  17  22  39  265  2  1  0   0  0  17.6   \n",
      "3541       Carson Palmer  QB  2016  17  21  35  265  2  1  0   0  0  17.6   \n",
      "3542        Landry Jones  QB  2016  17  19  30  225  2  1  1  10  0  17.0   \n",
      "3543    Colin Kaepernick  QB  2016  17  16  27  200  1  1  6  40  0  15.0   \n",
      "3544  Robert Griffin III  QB  2016  17  17  27  205  1  1  6  35  0  14.7   \n",
      "3545       Blake Bortles  QB  2016  17  24  40  255  1  1  2  10  0  14.2   \n",
      "3546           EJ Manuel  QB  2016  17  20  31  215  1  1  5  25  0  14.1   \n",
      "3547          Tom Savage  QB  2016  17  20  32  245  1  1  2   5  0  13.3   \n",
      "3548        Matt McGloin  QB  2016  17  20  34  230  1  1  2  10  0  13.2   \n",
      "3549         Andy Dalton  QB  2016  17  20  33  225  1  1  2  10  0  13.0   \n",
      "3550         Eli Manning  QB  2016  17  19  32  220  1  1  0   0  0  11.8   \n",
      "3551          Matt Moore  QB  2016  17  20  33  220  1  1  0   0  0  11.8   \n",
      "3552         Matt Cassel  QB  2016  17  18  29  215  1  2  2  10  0  11.6   \n",
      "3553    Ryan Fitzpatrick  QB  2016  17  18  31  225  1  2  0   0  0  11.0   \n",
      "3554          Jared Goff  QB  2016  17  13  26  180  1  1  1   5  0  10.7   \n",
      "3555        Mark Sanchez  QB  2016  17  14  22  165  1  1  2   5  0  10.1   \n",
      "3556        Dak Prescott  QB  2016  17   7  11   85  1  0  2  10  0   8.4   \n",
      "3557      Trevor Siemian  QB  2016  17   8  13   95  1  0  1   5  0   8.3   \n",
      "3558           Tony Romo  QB  2016  17   3   5   35  0  0  0   0  0   1.4   \n",
      "\n",
      "        13  \n",
      "0     35.3  \n",
      "1     14.9  \n",
      "2     16.4  \n",
      "3     25.1  \n",
      "4     17.3  \n",
      "5      8.0  \n",
      "6      1.0  \n",
      "7     22.3  \n",
      "8      1.3  \n",
      "9     28.3  \n",
      "10    24.7  \n",
      "11    10.8  \n",
      "12    12.7  \n",
      "13    17.0  \n",
      "14     8.5  \n",
      "15     8.5  \n",
      "16     5.0  \n",
      "17    16.8  \n",
      "18    23.2  \n",
      "19    24.4  \n",
      "20    25.8  \n",
      "21    20.7  \n",
      "22     7.8  \n",
      "23     6.8  \n",
      "24    19.2  \n",
      "25    12.8  \n",
      "26     7.2  \n",
      "27     9.1  \n",
      "28     3.5  \n",
      "29    11.2  \n",
      "...    ...  \n",
      "3529  29.6  \n",
      "3530  22.5  \n",
      "3531  23.9  \n",
      "3532  10.1  \n",
      "3533   8.7  \n",
      "3534  28.7  \n",
      "3535  11.9  \n",
      "3536  13.5  \n",
      "3537  18.9  \n",
      "3538  23.1  \n",
      "3539  28.4  \n",
      "3540  -1.0  \n",
      "3541  26.2  \n",
      "3542  27.1  \n",
      "3543  16.2  \n",
      "3544  20.5  \n",
      "3545  16.1  \n",
      "3546   2.2  \n",
      "3547  -0.9  \n",
      "3548   0.8  \n",
      "3549  15.4  \n",
      "3550   7.2  \n",
      "3551  18.2  \n",
      "3552  10.2  \n",
      "3553  20.4  \n",
      "3554   4.8  \n",
      "3555  -0.6  \n",
      "3556   2.4  \n",
      "3557  17.7  \n",
      "3558   7.2  \n",
      "\n",
      "[3559 rows x 14 columns]\n"
     ]
    }
   ],
   "source": [
    "print(players_test)\n",
    "print(players_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#print(table)\n",
    "#print(table.findAll('td', {\"class\":\"bodycontent\"}))\n",
    "#print([map(str,data.text.strip(' ')) for data in table.findAll('td', {\"class\":\"bodycontent\"})])\n",
    "playerdata = ','.join([data.text.strip(' ') for data in table.findAll('td', {\"class\":\"bodycontent\"})]).replace(u'\\xa0,\\xa0',u'').replace(u'\\xa0',u'').split(',')\n",
    "print(playerdata)\n",
    "\n",
    "print(table.findAll('td', {\"class\":\"bodycontent\"}).replace(u'\\xa0,\\xa0',u'').replace(u'\\xa0',u'').split(','))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.41204195  0.20651472  0.3306811  ..., -0.75863501 -0.18920211\n",
      "  -0.91081178]\n",
      " [ 0.18643062 -0.39225179 -0.89652853 ..., -0.31284331 -0.18920211\n",
      "  -1.02668095]\n",
      " [-1.40949623  0.80528123  0.12614616 ..., -0.75863501 -0.18920211\n",
      "   1.73100534]\n",
      " ..., \n",
      " [-1.01051452 -0.09286853 -0.07838878 ...,  1.91611518  5.28535329\n",
      "   0.34057528]\n",
      " [ 0.78490319  0.80528123  0.3306811  ..., -0.75863501 -0.18920211\n",
      "   0.43327061]\n",
      " [ 0.58541234  1.70343099  1.55789072 ..., -0.31284331 -0.18920211\n",
      "   0.68818279]] [ 11.   14.3  21.  ...,  33.5  12.9  14.7]\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n"
     ]
    }
   ],
   "source": [
    "# WIP!!!\n",
    "import tensorflow as tf\n",
    "import time as t\n",
    "import numpy as np\n",
    "\n",
    "trainData = np.load('trainData.npy')\n",
    "trainLabels = np.load('trainLabels.npy')\n",
    "\n",
    "# trainData reshape\n",
    "#trainData2 = trainData.reshape(1, len(trainData), np.shape(trainData)[1])\n",
    "\n",
    "# starting interactive session\n",
    "sess = tf.InteractiveSession()\n",
    "# symbolic variables/ placeholders\n",
    "x = tf.placeholder(tf.float32, shape=[None, 10])\n",
    "y_ = tf.placeholder(tf.float32, shape=[None, 1])#tf.transpose\n",
    "\n",
    "# now defining weights and biases\n",
    "W = tf.Variable(tf.zeros([10,1]))\n",
    "b = tf.Variable(tf.zeros([1]))\n",
    "\n",
    "# initialize global variables\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# build model\n",
    "y = tf.matmul(x,W) + b\n",
    "#cross_entropy = tf.reduce_mean(\n",
    "#    tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y))\n",
    "\n",
    "# Define loss\n",
    "cost = tf.reduce_mean(tf.square(y-y_))\n",
    "\n",
    "# train model\n",
    "train_step = tf.train.GradientDescentOptimizer(0.5).minimize(cost)#cross_entropy)\n",
    "batch_size = 1\n",
    "total_batch = int(len(trainLabels)/batch_size)\n",
    "avg_cost = 0\n",
    "idxs = np.array(range(len(trainData)))#range(total_batch - 1)\n",
    "np.random.shuffle(idxs)\n",
    "trainData2 = trainData[idxs,:]\n",
    "trainLabels2 = trainLabels[idxs]\n",
    "print(trainData2,trainLabels2)\n",
    "for i in range(total_batch):\n",
    "    batch = [trainData2[i*batch_size:(i+1)*batch_size,:],[trainLabels2[i*batch_size:(i+1)*batch_size]]]\n",
    "    #_, c = sess.run([train_step,cost],feed_dict={x: batch[0], y_: batch[1]})\n",
    "    #avg_cost += c / total_batch\n",
    "    #print(batch[0],batch[1])\n",
    "    train_step.run(feed_dict={x: batch[0], y_: batch[1]})\n",
    "#batch = [trainData[i*batch_size:(i+1)*batch_size],trainLabels[i*batch_size:(i+1)*batch_size]] \n",
    "# check accuracy\n",
    "correct_prediction = tf.equal(y,y_)#tf.argmax(y,1), tf.argmax(y_,1))\n",
    "#accuracy = #tf.reduce_mean(tf.cast(cost, tf.float32))#correct_prediction, tf.float32))\n",
    "a = 0.\n",
    "for i in range(total_batch):#idxs\n",
    "    batch = [trainData2[i*batch_size:(i+1)*batch_size,:],[trainLabels2[i*batch_size:(i+1)*batch_size]]]\n",
    "    #print(batch)\n",
    "    #_, c = sess.run([train_step,cost],feed_dict={x: batch[0], y_: batch[1]})\n",
    "    #avg_cost += c / total_batch\n",
    "    #print(batch[0],batch[1])\n",
    "    a += cost.eval(feed_dict={x: batch[0], y_: batch[1]})#accuracy\n",
    "    print(a)\n",
    "print(a/total_batch)\n",
    "#print (\"cost=\",\"{:.9f}\".format(avg_cost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('trainData.npy',trainData)\n",
    "np.save('trainLabels.npy',trainLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot feed value of shape (10,) for Tensor 'Placeholder_18:0', which has shape '(?, 10)'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-433bca870e35>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtrainData2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtrainLabels2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/py36/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36meval\u001b[0;34m(self, feed_dict, session)\u001b[0m\n\u001b[1;32m    539\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m     \"\"\"\n\u001b[0;32m--> 541\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_eval_using_default_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/py36/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_eval_using_default_session\u001b[0;34m(tensors, feed_dict, graph, session)\u001b[0m\n\u001b[1;32m   4083\u001b[0m                        \u001b[0;34m\"the tensor's graph is different from the session's \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4084\u001b[0m                        \"graph.\")\n\u001b[0;32m-> 4085\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4086\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4087\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/py36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/py36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 \u001b[0;34m'Cannot feed value of shape %r for Tensor %r, '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1099\u001b[0m                 \u001b[0;34m'which has shape %r'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m                 % (np_val.shape, subfeed_t.name, str(subfeed_t.get_shape())))\n\u001b[0m\u001b[1;32m   1101\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_feedable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubfeed_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Tensor %s may not be fed.'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0msubfeed_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot feed value of shape (10,) for Tensor 'Placeholder_18:0', which has shape '(?, 10)'"
     ]
    }
   ],
   "source": [
    "print(accuracy.eval(feed_dict={x: trainData2[0], y_: [trainLabels2[0]]}))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
